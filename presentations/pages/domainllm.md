# Domain Specific LLM
[<img src="../images/back.png">](../presentation)

### What is
- LLM that is trained or fine-tuned to execute tasks that are well-defined and guided by organizational policies.
- Unlike general-purpose LLM, domain-specific LLMs are designed to service a specific purpose on domain specific applications.
- Models trained to understand their context, which includes data related to their product, corporate policies and industry-specific terminologies.

### Key benefits of domain-specific LLMs
- Precision and expertise
  - Fine-tuned on datasets from specialized domains, enabling generating results that are not only accurate but also more relevant to a specific business
  - General models lack the ability to understand specific contexts beyond the vast datasets they were trained on.
  - General-purpose LLMs may occasionally generate incorrect information, referred to as hallucinations.
  - Since generic LLMs lack expertise in any specific domain, their information on niche topics may be overly generalized or inaccurate, limiting their suitability for specialized tasks.
  - Due to their extensive data requirements, training and using general-purpose LLMs can be computationally expensive and time-consuming, making them less convenient for many applications.
- Enhanced reliability
  - Through their narrowed focus, these models are less vulnerable to external and irrelevant information. 
  - Ensuring more consistent and reliable outputs.
- Safety and liability
  - Misinformed output can be detrimental.
  - Domain-specific LLMs, often embedded with additional safety mechanisms, can deliver more trustworthy insights.
- Improved user experience
  - able to understand its specific jargon and contex
  - leads to a more gratifying user interaction.
- Model efficiency
  - Instead of relying on a massive general-purpose model, it's often more efficient to fine-tune a smaller model on a domain-specific dataset.
  - This smaller model can offer higher quality outputs at a significantly lower cost.

### One way to tailoring your SLM for domain specificity is fine-Tuning or model tuning (tailoring)
- Prepare your datasets and have a model ready for training
- Move on to quantization and inference—steps crucial for optimizing the model’s performance to run efficiently in production environments
- Quantization is essentially about reducing the precision of numbers used during calculations—this helps speed up processing times significantly while maintaining satisfactory accuracy levels.


[<img src="../images/back.png">](../presentation)
